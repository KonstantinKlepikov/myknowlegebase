<!DOCTYPE html>
<html lang="ru_RU">

  <head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Lightgbm | My knowledge base</title>
<meta name="generator" content="Jekyll v3.8.7" />
<meta property="og:title" content="Lightgbm" />
<meta property="og:locale" content="ru_RU" />
<meta name="description" content="Градиент бустинг фреймворк LightGBM" />
<meta property="og:description" content="Градиент бустинг фреймворк LightGBM" />
<link rel="canonical" href="https://konstantinklepikov.github.io/myknowlegebase/notes/lightgbm.html" />
<meta property="og:url" content="https://konstantinklepikov.github.io/myknowlegebase/notes/lightgbm.html" />
<meta property="og:site_name" content="My knowledge base" />
<script type="application/ld+json">
{"description":"Градиент бустинг фреймворк LightGBM","@type":"WebPage","url":"https://konstantinklepikov.github.io/myknowlegebase/notes/lightgbm.html","headline":"Lightgbm","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

    <meta name="keywords" content="">
    <link href="https://fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet">
    <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">

    
    
    <link rel="stylesheet" href="https://konstantinklepikov.github.io/myknowlegebase/assets/style.css">
    <script async defer src="https://buttons.github.io/buttons.js"></script>

    <!-- start custom head snippets, customize with your own _includes/head-custom.html file -->


      <!-- Yandex.Metrika counter -->
  <script type="text/javascript" >
    (function(m,e,t,r,i,k,a){m[i]=m[i]||function(){(m[i].a=m[i].a||[]).push(arguments)};
    m[i].l=1*new Date();k=e.createElement(t),a=e.getElementsByTagName(t)[0],k.async=1,k.src=r,a.parentNode.insertBefore(k,a)})
    (window, document, "script", "https://mc.yandex.ru/metrika/tag.js", "ym");

    ym(53548570, "init", {
        clickmap:true,
        trackLinks:true,
        accurateTrackBounce:true
    });
  </script>
  <noscript><div><img src="https://mc.yandex.ru/watch/53548570" style="position:absolute; left:-9999px;" alt="" /></div></noscript>
    <!-- /Yandex.Metrika counter -->
      <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-139620627-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-139620627-1');
  </script>


<!-- Favicon -->
<link rel="icon" href="https://konstantinklepikov.github.io/myknowlegebase/assets/img/favicon.ico" type="image/x-icon">
<link rel="shortcut icon" href="https://konstantinklepikov.github.io/myknowlegebase/assets/img/favicon.ico" type="image/x-icon">

<!-- Math support -->
<!-- Mathjax Support -->
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async></script>

<!-- tags collection-->

    







<!-- end custom head snippets -->

</head>

  <body>

    <header class="border-bottom-thick px-2 clearfix">
    <div class="left sm-width-full py-1 mt-1 mt-lg-0">
      <a class="align-middle link-primary text-accent" href="https://konstantinklepikov.github.io/">
        My deep learning
      </a>
    </div>
    <div class="right sm-width-full">
      <ul class="list-reset mt-lg-1 mb-2 mb-lg-1">
        <li class="inline-block">
          <a class="align-middle link-primary mr-2 mr-lg-0 ml-lg-2" href="/myknowlegebase/">
            My knowledge base
          </a>
        </li>
      </ul>
    </div>
  </header>

    <main role="main">

      
<article class="container mx-auto px-2 mt2 mb4">
  <header>
    <h1 class="h1 col-9 sm-width-full py-4 mt-3 inline-block" itemprop="name headline">Lightgbm</h1>
  </header>
  <div class="col-4 sm-width-full border-top-thin">
    <p class="mb-3 h5">Теги:
      
        
        <a href="/myknowlegebase/tag/machine-learning" title="machine-learning" class="link-tags">machine-learning&nbsp;</a>
      
        
        <a href="/myknowlegebase/tag/pip" title="pip" class="link-tags">pip&nbsp;</a>
      
    </p>
  </div>
  <div>
    <script type="text/javascript"> function googleTranslateElementInit() { new google.translate.TranslateElement({pageLanguage: 'ru'}, 'google_translate_element'); } </script> <script type="text/javascript" src="//[translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script>
  </div>
  <div class="prose mb-4 py-4">
    <p>Градиент бустинг фреймворк LightGBM для ml</p>

<p>LightGBM is a gradient boosting framework that uses tree based learning algorithms. It is designed to be distributed and efficient with the following advantages:</p>

<ul>
  <li>Faster training speed and higher efficiency.</li>
  <li>Lower memory usage.</li>
  <li>Better accuracy.</li>
  <li>Support of parallel, distributed, and GPU learning.</li>
  <li>Capable of handling large-scale data.</li>
</ul>

<p><a href="https://lightgbm.readthedocs.io/en/latest/index.html">Ссылка на документацию</a></p>

<h2 id="python-quik-start">Python quik start</h2>

<p><a href="https://lightgbm.readthedocs.io/en/latest/Python-Intro.html">Статья</a></p>

<p><code class="language-plaintext highlighter-rouge">pip install lightgbm</code></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">lightgbm</span> <span class="k">as</span> <span class="n">lgb</span>
</code></pre></div></div>

<p>The LightGBM Python module can load data from:</p>

<ul>
  <li>LibSVM (zero-based)/TSV/CSV/ XT format file</li>
  <li>NumPy 2D array(s), pandas DataFrame, H2O DataTable’s Frame, SciPy sparse matrix</li>
  <li>LightGBM binary file</li>
  <li>LightGBM <code class="language-plaintext highlighter-rouge">Sequence</code> object(s)</li>
</ul>

<p>The data is stored in a <code class="language-plaintext highlighter-rouge">Dataset</code> object.</p>

<p>To load a LibSVM <strong>(zero-based)</strong> text file or a LightGBM binary file into Dataset:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_data</span> <span class="o">=</span> <span class="n">lgb</span><span class="p">.</span><span class="n">Dataset</span><span class="p">(</span><span class="s">'train.svm.bin'</span><span class="p">)</span>
</code></pre></div></div>

<p>To load a <strong>numpy array</strong> into Dataset:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">500</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>  <span class="c1"># 500 entities, each contains 10 features
</span><span class="n">label</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>  <span class="c1"># binary target
</span><span class="n">train_data</span> <span class="o">=</span> <span class="n">lgb</span><span class="p">.</span><span class="n">Dataset</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">label</span><span class="p">)</span>
</code></pre></div></div>

<p>To load a <strong>scipy.sparse.csr_matrix array</strong> into Dataset:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">scipy</span>
<span class="n">csr</span> <span class="o">=</span> <span class="n">scipy</span><span class="p">.</span><span class="n">sparse</span><span class="p">.</span><span class="n">csr_matrix</span><span class="p">((</span><span class="n">dat</span><span class="p">,</span> <span class="p">(</span><span class="n">row</span><span class="p">,</span> <span class="n">col</span><span class="p">)))</span>
<span class="n">train_data</span> <span class="o">=</span> <span class="n">lgb</span><span class="p">.</span><span class="n">Dataset</span><span class="p">(</span><span class="n">csr</span><span class="p">)</span>
</code></pre></div></div>

<p>Load from <strong>Sequence objects</strong>. We can implement <code class="language-plaintext highlighter-rouge">Sequence</code> interface to read binary files. The following example shows reading HDF5 file with <code class="language-plaintext highlighter-rouge">h5py</code>:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">h5py</span>

<span class="k">class</span> <span class="nc">HDFSequence</span><span class="p">(</span><span class="n">lgb</span><span class="p">.</span><span class="n">Sequence</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hdf_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">hdf_dataset</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>

    <span class="k">def</span> <span class="nf">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="p">.</span><span class="n">data</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">data</span><span class="p">)</span>

<span class="n">f</span> <span class="o">=</span> <span class="n">h5py</span><span class="p">.</span><span class="n">File</span><span class="p">(</span><span class="s">'train.hdf5'</span><span class="p">,</span> <span class="s">'r'</span><span class="p">)</span>
<span class="n">train_data</span> <span class="o">=</span> <span class="n">lgb</span><span class="p">.</span><span class="n">Dataset</span><span class="p">(</span><span class="n">HDFSequence</span><span class="p">(</span><span class="n">f</span><span class="p">[</span><span class="s">'X'</span><span class="p">],</span> <span class="mi">8192</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="n">f</span><span class="p">[</span><span class="s">'Y'</span><span class="p">][:])</span>
</code></pre></div></div>

<p><strong>Saving Dataset into a LightGBM binary file will make loading faster:</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_data</span> <span class="o">=</span> <span class="n">lgb</span><span class="p">.</span><span class="n">Dataset</span><span class="p">(</span><span class="s">'train.svm.txt'</span><span class="p">)</span>
<span class="n">train_data</span><span class="p">.</span><span class="n">save_binary</span><span class="p">(</span><span class="s">'train.bin'</span><span class="p">)</span>
</code></pre></div></div>

<p><strong>Create validation data</strong>. In LightGBM, the validation data should be aligned with training data.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">validation_data</span> <span class="o">=</span> <span class="n">train_data</span><span class="p">.</span><span class="n">create_valid</span><span class="p">(</span><span class="s">'validation.svm'</span><span class="p">)</span>
<span class="c1"># or
</span><span class="n">validation_data</span> <span class="o">=</span> <span class="n">lgb</span><span class="p">.</span><span class="n">Dataset</span><span class="p">(</span><span class="s">'validation.svm'</span><span class="p">,</span> <span class="n">reference</span><span class="o">=</span><span class="n">train_data</span><span class="p">)</span>
</code></pre></div></div>

<p><strong>Specific feature names and categorical features</strong>:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_data</span> <span class="o">=</span> <span class="n">lgb</span><span class="p">.</span><span class="n">Dataset</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">label</span><span class="p">,</span> <span class="n">feature_name</span><span class="o">=</span><span class="p">[</span><span class="s">'c1'</span><span class="p">,</span> <span class="s">'c2'</span><span class="p">,</span> <span class="s">'c3'</span><span class="p">],</span> <span class="n">categorical_feature</span><span class="o">=</span><span class="p">[</span><span class="s">'c3'</span><span class="p">])</span>
</code></pre></div></div>

<p>LightGBM can use categorical features as input directly. It doesn’t need to convert to one-hot encoding, and is much faster than one-hot encoding (about 8x speed-up). But you should convert your categorical features to int type before you construct Dataset.</p>

<p><strong>Weights can be set when needed</strong>:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">500</span><span class="p">,</span> <span class="p">)</span>
<span class="n">train_data</span> <span class="o">=</span> <span class="n">lgb</span><span class="p">.</span><span class="n">Dataset</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">label</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="n">w</span><span class="p">)</span>
<span class="c1"># or
</span><span class="n">train_data</span> <span class="o">=</span> <span class="n">lgb</span><span class="p">.</span><span class="n">Dataset</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">label</span><span class="p">)</span>
<span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">500</span><span class="p">,</span> <span class="p">)</span>
<span class="n">train_data</span><span class="p">.</span><span class="n">set_weight</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
</code></pre></div></div>

<p>And you can use <code class="language-plaintext highlighter-rouge">Dataset.set_init_score()</code> to set initial score, and <code class="language-plaintext highlighter-rouge">Dataset.set_group()</code> to set group/query data for ranking tasks.</p>

<p><strong>Setting parameters</strong>:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Booster parameters
</span><span class="n">param</span> <span class="o">=</span> <span class="p">{</span><span class="s">'num_leaves'</span><span class="p">:</span> <span class="mi">31</span><span class="p">,</span> <span class="s">'objective'</span><span class="p">:</span> <span class="s">'binary'</span><span class="p">}</span>
<span class="n">param</span><span class="p">[</span><span class="s">'metric'</span><span class="p">]</span> <span class="o">=</span> <span class="s">'auc'</span>
<span class="c1"># You can also specify multiple eval metrics
</span><span class="n">param</span><span class="p">[</span><span class="s">'metric'</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="s">'auc'</span><span class="p">,</span> <span class="s">'binary_logloss'</span><span class="p">]</span>
</code></pre></div></div>

<p><strong>Training</strong>:</p>

<p>Training a model requires a parameter list and data set</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">num_round</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">bst</span> <span class="o">=</span> <span class="n">lgb</span><span class="p">.</span><span class="n">train</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">train_data</span><span class="p">,</span> <span class="n">num_round</span><span class="p">,</span> <span class="n">valid_sets</span><span class="o">=</span><span class="p">[</span><span class="n">validation_data</span><span class="p">])</span>

<span class="c1"># After training, the model can be saved
</span><span class="n">json_model</span> <span class="o">=</span> <span class="n">bst</span><span class="p">.</span><span class="n">dump_model</span><span class="p">()</span>

<span class="c1"># A saved model can be loaded
</span><span class="n">bst</span> <span class="o">=</span> <span class="n">lgb</span><span class="p">.</span><span class="n">Booster</span><span class="p">(</span><span class="n">model_file</span><span class="o">=</span><span class="s">'model.txt'</span><span class="p">)</span>  <span class="c1"># init model
</span></code></pre></div></div>

<p><strong>Training with 5-fold CV</strong>:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">lgb</span><span class="p">.</span><span class="n">cv</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">train_data</span><span class="p">,</span> <span class="n">num_round</span><span class="p">,</span> <span class="n">nfold</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</code></pre></div></div>

<p><strong>Early Stopping</strong>:</p>

<p>If you have a validation set, you can use early stopping to find the optimal number of boosting rounds. Early stopping requires at least one set in <code class="language-plaintext highlighter-rouge">valid_sets</code>. If there is more than one, it will use all of them except the training data</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">bst</span> <span class="o">=</span> <span class="n">lgb</span><span class="p">.</span><span class="n">train</span><span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">train_data</span><span class="p">,</span> <span class="n">num_round</span><span class="p">,</span> <span class="n">valid_sets</span><span class="o">=</span><span class="n">valid_sets</span><span class="p">,</span> <span class="n">early_stopping_rounds</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">bst</span><span class="p">.</span><span class="n">save_model</span><span class="p">(</span><span class="s">'model.txt'</span><span class="p">,</span> <span class="n">num_iteration</span><span class="o">=</span><span class="n">bst</span><span class="p">.</span><span class="n">best_iteration</span><span class="p">)</span>
</code></pre></div></div>

<p>The model will train until the validation score stops improving. Validation score needs to improve at least every <code class="language-plaintext highlighter-rouge">early_stopping_rounds</code> to continue training</p>

<p><strong>Prediction</strong>:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 7 entities, each contains 10 features
</span><span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">ypred</span> <span class="o">=</span> <span class="n">bst</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</code></pre></div></div>

<p>If early stopping is enabled during training, you can get predictions from the best iteration with <code class="language-plaintext highlighter-rouge">bst.best_iteration</code></p>

<h2 id="как-устроен-lightgbm">Как устроен LightGBM</h2>

<p><a href="https://lightgbm.readthedocs.io/en/latest/Features.html">Читай тут</a></p>

<h2 id="параметры">Параметры</h2>

<p><a href="https://lightgbm.readthedocs.io/en/latest/Parameters.html">Читай тут</a></p>

<p><a href="https://sites.google.com/view/lauraepp/parameters">Интерактивное описание параметров</a></p>

<p>Format</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">params</span> <span class="o">=</span> <span class="p">{</span>
   <span class="s">"monotone_constraints"</span><span class="p">:</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="p">}</span>
</code></pre></div></div>

<h3 id="parameters-tuning">Parameters Tuning</h3>

<p>[<a href="lightgbm-parameters-tuning" title="Lightgbm parameters tuning">lightgbm-parameters-tuning</a>]</p>

<ul>
  <li><a href="https://github.com/microsoft/FLAML">Autotuning with FLAWL</a></li>
  <li><a href="https://github.com/microsoft/FLAML">Autotuning with Optuna</a></li>
</ul>

<p>Несколько подходов, достыпных в lightgbm:</p>

<ul>
  <li><a href="https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html#tune-parameters-for-the-leaf-wise-best-first-tree">Tune Parameters for the Leaf-wise (Best-first) Tree</a></li>
  <li><a href="https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html#for-faster-speed">For Faster Speed</a></li>
  <li><a href="https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html#for-better-accuracy">For Better Accuracy</a></li>
  <li><a href="https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html#deal-with-over-fitting">Deal with Over-fitting</a></li>
</ul>

<p><a href="https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html#deal-with-over-fitting">Полностю статья</a></p>

<h2 id="python-api">Python API</h2>

<p><a href="https://lightgbm.readthedocs.io/en/latest/Python-API.html">см.тут</a></p>

<h2 id="gpu-tutorial">GPU tutorial</h2>

<p><a href="https://lightgbm.readthedocs.io/en/latest/GPU-Tutorial.html#lightgbm-gpu-tutorial">см.тут</a></p>

<h2 id="advanced-topics">Advanced Topics</h2>

<p><a href="https://lightgbm.readthedocs.io/en/latest/Advanced-Topics.html">см.тут</a></p>

<ul>
  <li>Missing Value Handle</li>
  <li>Categorical Feature Support</li>
  <li>LambdaRank</li>
  <li>Cost Efficient Gradient Boosting</li>
</ul>


  </div>
</article>


    </main>

    <footer role="banner">
<div class="border-top-thin clearfix mt-2 mt-lg-4">
    <div class="container mx-auto px-2">
      <p class="col-8 sm-width-full left py-2 mb-0"><a href="/myknowlegebase/">My knowledge base</a> проект поддерживается <a class="text-accent" href="https://github.com/KonstantinKlepikov">KonstantinKlepikov</a></p>
      <ul class="list-reset right clearfix sm-width-full py-2 mb-2 mb-lg-0">
        <li class="inline-block mr-1">
          <a href="https://twitter.com/share" class="twitter-share-button" data-hashtags="My knowledge base">Tweet</a> <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
        </li>
      </ul>
    </div>
  </div>
</footer>

  </body>

</html>

<script type="text/javascript">
  // Hack: Replace page-link with "Page Title"
  document.querySelectorAll(".markdown-body a[title]").forEach((a) => {
    a.innerText = a.title;
  });
  // Hack: Remove .md extension from wikilinks to get the html in jekyll
  document.querySelectorAll("a").forEach(l => {
    if (l.href.endsWith('.md')) {
      l.href = l.href.substring(0, l.href.length-3)
    }
  })
</script>