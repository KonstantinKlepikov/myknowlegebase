<!DOCTYPE html>
<html lang="ru_RU">

  <head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Ab-tests | My knowledge base</title>
<meta name="generator" content="Jekyll v3.8.7" />
<meta property="og:title" content="Ab-tests" />
<meta property="og:locale" content="ru_RU" />
<meta name="description" content="Как построить систему аб-тестирования в компании" />
<meta property="og:description" content="Как построить систему аб-тестирования в компании" />
<link rel="canonical" href="https://konstantinklepikov.github.io/myknowlegebase/notes/ab-tests.html" />
<meta property="og:url" content="https://konstantinklepikov.github.io/myknowlegebase/notes/ab-tests.html" />
<meta property="og:site_name" content="My knowledge base" />
<script type="application/ld+json">
{"@type":"WebPage","url":"https://konstantinklepikov.github.io/myknowlegebase/notes/ab-tests.html","headline":"Ab-tests","description":"Как построить систему аб-тестирования в компании","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

    <meta name="keywords" content="">
    <link href="https://fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet">
    <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">

    
    
    <link rel="stylesheet" href="https://konstantinklepikov.github.io/myknowlegebase/assets/style.css">
    <script async defer src="https://buttons.github.io/buttons.js"></script>

    <!-- start custom head snippets, customize with your own _includes/head-custom.html file -->


      <!-- Yandex.Metrika counter -->
  <script type="text/javascript" >
    (function(m,e,t,r,i,k,a){m[i]=m[i]||function(){(m[i].a=m[i].a||[]).push(arguments)};
    m[i].l=1*new Date();k=e.createElement(t),a=e.getElementsByTagName(t)[0],k.async=1,k.src=r,a.parentNode.insertBefore(k,a)})
    (window, document, "script", "https://mc.yandex.ru/metrika/tag.js", "ym");

    ym(53548570, "init", {
        clickmap:true,
        trackLinks:true,
        accurateTrackBounce:true
    });
  </script>
  <noscript><div><img src="https://mc.yandex.ru/watch/53548570" style="position:absolute; left:-9999px;" alt="" /></div></noscript>
    <!-- /Yandex.Metrika counter -->
      <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-139620627-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-139620627-1');
  </script>


<!-- Favicon -->
<link rel="icon" href="https://konstantinklepikov.github.io/myknowlegebase/assets/img/favicon.ico" type="image/x-icon">
<link rel="shortcut icon" href="https://konstantinklepikov.github.io/myknowlegebase/assets/img/favicon.ico" type="image/x-icon">

<!-- Math support -->
<!-- Mathjax Support -->
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async></script>

<!-- tags collection-->

    







<!-- end custom head snippets -->

</head>

  <body>

    <header class="border-bottom-thick px-2 clearfix">
    <div class="left sm-width-full py-1 mt-1 mt-lg-0">
      <a class="align-middle link-primary text-accent" href="https://konstantinklepikov.github.io/">
        My deep learning
      </a>
    </div>
    <div class="right sm-width-full">
      <ul class="list-reset mt-lg-1 mb-2 mb-lg-1">
        <li class="inline-block">
          <a class="align-middle link-primary mr-2 mr-lg-0 ml-lg-2" href="/myknowlegebase/">
            My knowledge base
          </a>
        </li>
      </ul>
    </div>
  </header>

    <main role="main">

      
<article class="container mx-auto px-2 mt2 mb4">
  <header>
    <h1 class="h1 col-9 sm-width-full py-4 mt-3 inline-block" itemprop="name headline">Ab-tests</h1>
  </header>
  <div class="col-4 sm-width-full border-top-thin">
    <p class="mb-3 h5">Теги:
      
        
        <a href="/myknowlegebase/tag/tests" title="tests" class="link-tags">tests&nbsp;</a>
      
      </p>
  </div>
  <div class="prose mb-4 py-4">
    <p><strong>OEC (общий критерий оценки)</strong> - количесивенный показатель цели эксперимента (реакция, зависимая переменная, результат, оценка или функция пригодности. Если целей несколько - применяется сбалансированная система показателей.)</p>

<p><strong>Параметр</strong> - контроллируемая экспериментальная переменная, которая, как ожидается, влияет на OEC и другие показатели. Иногда называют фактоармси или переменными. Параметрам часто присваивают значения, называемые уровнями. В простом аб-тесте обычно используют один параметр с двумя уровнями, в онлайн-экспериментах обычно используется несколько уровней. Мультивариантные тесты оценивают несколько параметров совместно.</p>

<p><strong>Вариант</strong> - тестируемый пользовательский опыт, обычно путем присвоения значений параметрам. В простом аб-тесте варианты А и Б - это два варианта, контрольный и тестовый. Иногда под вариантом понимают только тестовый вариант.</p>

<p><strong>Рандомизатор</strong> - псевдослучайный процесс, применяемый к объектам эксперимента для сопоставления их с вариантами.</p>

<p><strong>Три основных постулата для организаций, которые хотят проводить контроллируемые онлайн-эксперименты</strong>:</p>

<ol>
  <li>Организация хочет принимать решения на основе данных и официально оформила OEC</li>
  <li>Организация готова инвестировать в инфраструктуру и тесты, чтобы проводить эксперименты и гарантировать достоверность</li>
  <li>Организация признает, что плохо умеет оценивать значимость целей</li>
</ol>

<p><strong>Статистическая мощность (statistical power)</strong> - вероятность обнаружения значимого различия между вариантами, когда эта разница действительно есть. Каждый эксперимент должен обладать достаточной стат.мощностью, чтобы с высокой вероятностью сделать вывод о том, привел ли эксперимент к более значимым изменеениям, чем предполагалось. Чем больше выборка, тем больше мощность. Обычно эксперимент планируется при мощности 80-90%…</p>

<p>Для разработки эксперимента надо определить следующие вещи:</p>

<ul>
  <li>единицу рандомизации</li>
  <li>популяцию единиц рандомизации</li>
  <li>размер (по охвату) эксперимента</li>
  <li>длительность эксперимента</li>
  <li>насколько безопасен эксперимент</li>
  <li>надо-ли разделять трафик с другими экспериментами</li>
</ul>

<p>На длительность экспермента влияют:</p>

<ul>
  <li>рост числа пользователей</li>
  <li>эффект недели/времени дня</li>
  <li>сезонность</li>
  <li>эффект новизны и первичности</li>
</ul>

<p>Для проведения эксперимента требуется:</p>

<ul>
  <li>инструмент записи и получения данных журналов</li>
  <li>инфраструктура для организации тестов (конфигуратор тестов, назначение вариантов и т.д.)</li>
</ul>

<p>Для внедрения результатов необходимо найти компромисс между ценой внедрения и ценностью. Необходимо учитывать стоимость обслуживания после внедрения улучшений. Модель внедрения такая:</p>

<ol>
  <li>результат не является стат.значимым и практически не важен - можно повторить эту идею в тесте или отказаться от нее</li>
  <li>результат статистически и практически значим - запускать</li>
  <li>результат значим статистически, но не практически. Необходима оценка стоимости и других факторов запуска.</li>
  <li>доверительные интерфвалы выходят за рамки практической значимости, статистическая значимость незначительна - недостаточно данных или стат.мощности эксперимента.</li>
  <li>результат значим практически, но не статистически. Нужен повторный тест.</li>
  <li>результат статистически значим и. вероятно, значим практически - повторить тест.</li>
</ol>

<p><strong>Закон Тваймана</strong> - любая статистика, которая выглядит интересно, почти наверняка неверна. Причины:</p>

<ul>
  <li>нехватка стат.мощности</li>
  <li>неверная интерпретация p-значений</li>
  <li>отслеживание p-значений</li>
  <li>множественные проверки одной гипотезы (использование разных методов для получения ожидаемого результата)</li>
</ul>

<p><strong>Доверительный интервал</strong> - количественно определенная степень неопределенности эффекта от измерения. Уровень доверия показывает как часто интервал должен содержать истинный эффект от воздействия.</p>

<p><strong>Внутренняя достоверность</strong> - относится к правильности экспериментальных результатов, которые не обобщают на другие популяции или периоды времени. Угрозы:</p>

<ol>
  <li>нарушение правила SUTVA (допущение о стабильном влиянии на экспериментальный объект) - предполагается, что объекты эксперимента не влияют друг на друга</li>
  <li>ошибка выжившего - оценка тех, кто дожил до конца эксперимента</li>
  <li>вынужденное воздействие - неслучай   ное распределение вариантов</li>
  <li>несоответствие коэффициента выборки (соотношение объектов между вариантами значительно отличается от задуманного). Это может быть обусловлено редиректами. ботами, различиями в производительности серверов и т.д.</li>
</ol>

<p><strong>Внешняя достоверность</strong> отображает степень, в которой результаты контроллируемого эксперимента могут быть обобщены на другие выборки и с течением времени. Угрозы:</p>

<ol>
  <li>эффект первичности - пользователям может потребоваться время для адаптации к изменеениям</li>
  <li>эффект новизны - непродолжительный ээффект, вызванный интересом пользователей к измененеиям</li>
</ol>

<p><strong>Парадокс Симпсона</strong> - если мы проводим эксперимент с накоплением, т.е. имеем два или более периода с разными процентными долями распределения вариантов, объединение результатов может привести к смещенной неверной оценке эффектов воздействия, т.е. тест может быть лучше, чем контроль как в первой. так и во второй фазе, но в целом хуже, когда два периода объединены. Возможна и инверсия парадокса.</p>

<h2 id="модели-зрелости-эксперитмента">Модели зрелости эксперитмента</h2>

<ol>
  <li><strong>Запуск</strong> - строительство фундамента экспериментальной платформы, подбор экспериментов и базовых методов науки о данных, для вычисления сводной статистики, задействованной в проверке гипотез.</li>
  <li><strong>Разбег</strong> - переход от проведения нескольких экспериментов к определению стандартных показателей и побуждению организации к проведению дополнительных экспериментов. На этом этапе повышается доверие, проводятся А/А тесты и тесты на соответствие отношения выборок (SRM)</li>
  <li><strong>Взлет</strong> - переход к масштабному проведению экспериментов. Эксперименты используются для оценки большинства новых функций и измененеия</li>
  <li><strong>Полет</strong> - А/Б тесты становятся нормой каждого измененеия. Должно анализироваться большинство экспериментов, особенно простых, без помощи специалистов по данным. Акцент смещается на автоматизацию</li>
</ol>

<h2 id="организационные-показатели-экспериментов">Организационные показатели экспериментов</h2>

<ul>
  <li><strong>целевые показатели (goal metrics)</strong>, метрики успеха или показатели истинного севера, отражают то, что в конечном итоге волнует компанию.</li>
  <li><strong>показатели движущей силы (driver metrics)</strong> или метрики дорожного указателя или суррогатные или косвенные метрики- более краткосрочные метрики, отражают причинно-следственную модель того, что требуется для успеха компании, т.е. гипотезы о факторах успеха.</li>
  <li><strong>ограничительные показатели</strong> - защищают от ошибочных гипотез и бывают двух типов - показатели, защищающие бизнес и показатели оценивающие внутреннюю достоверность результатов.</li>
</ul>

<p>Кроме того, могут учитываться показатели активов и вовлеченности (к примеру число пользователей и ценность, которую пользователи получают от сервиса) и бизнес-метрики и операционные показатели (например выручка на пользователя). А еще показатели качества данных, диагностически или отладочные показатели.</p>

<p><strong>Как выбрать показатели?</strong> Убедитесь, что целевые показатели:</p>

<ul>
  <li>простые</li>
  <li>стабильные</li>
</ul>

<p>Убедитесь, что показатели движущих сил:</p>

<ul>
  <li>согласованы с целью</li>
  <li>практичны и актуальны</li>
  <li>чувствительны</li>
  <li>устойчивы к манипуляциям</li>
</ul>

<p><strong>Как выработать показатели?</strong></p>

<ul>
  <li>использовать гипотезы из менее масштабируемых методов для генерации идей, а затем проверять их в масштабируемом анализе данных для уточнения формулировки</li>
  <li>учитывать качество при определении целей или показателей движущих сил (например учитывать плохие или хорошие клики)</li>
  <li>включать только интерпретируемые модели и подтверждаемые с течением времени модели</li>
  <li>измерять то, что ненужно точно, чем неявно то, что хотите (например недовольство пользователей, а не удовлетворенность)</li>
  <li>показатели сами по себе косвенны - всегда есть набор неподходящих случаев</li>
</ul>

<p><strong>При оценке показателей следует</strong>:</p>

<ul>
  <li>использовать альтернативные источники данных</li>
  <li>анализ данных наблюдений</li>
  <li>опыт других компаний</li>
  <li>проводить экспериме6нты, целью которых является оценка показателей</li>
  <li>использовать исторические данные экспериментов</li>
</ul>

<p><strong>Показатели экспериментов должны быть:</strong></p>

<ul>
  <li>измеримыми</li>
  <li>назначемыми (должна быть возморжность присвоить занчения показателей экспериментальному варианту)</li>
  <li>чувствительными и своевременными (чтобы своевременно обнаруживать важные изменеения)</li>
</ul>

<p><strong>Как объединять показатели в OEC?</strong></p>

<ul>
  <li>выбрать наиболее значимый показатель (one metrics that matter OMTM)</li>
  <li>выбрать чрезвычайно важную цель (wildly important goal WIG)</li>
  <li>сформулировать взвешенный единый показатель с учетом их важности (взвешенная сумма показателей)</li>
  <li>нормализовать каждый из показателей к заранее заданному диапазону и присвоить каждому вес (взвешенная сумма нормализованных показателей)</li>
</ul>

<p>При этом есть четыре подхода к внедрению:</p>

<ul>
  <li>если все ключевые показатели статистически не значимы или статистически значимы или хотя бы один ключевой показатель статистически значим, то следует внедрить изменение</li>
  <li>если все ключевые показатели не значимы или  отрицательны или один показатель отрицателооен, следует отменить внедрение</li>
  <li>если ничего не изменилось, следует подумать об увеличе6нии стат.мощности, прежде чем внедрять</li>
  <li>если часть положительна, а часть отрицательна, следует исходить из компромиссов.</li>
</ul>

<p>Чтобы объединить метрики в OEC, часто ест ьсмысл сократить их число.</p>

<p><strong>Закон Гудхарда</strong>. Любая наблюдаемая статистическая закономерность будет иметь тенденцию разрушаться, как только на нее будет оказано давление в целях контроля. Или, сокращенно, “когда мера становится целью, она перестает быть хорошей мерой”.</p>

<p><strong>Закон Кэмпбелла</strong>. Чем чаще какой-либо количественный социальный показатель используется для принятия социальных решений, тем больше он будет подвержен коррупционному давлению и тем более склонен к искажению и разрушению социальных процессов, для отслеживания которых он предназначен. Замечание Лукаса к нему: “взаимосвязи, наблюдаемые в исторических данных, не могут считаться структурными или причинными. Политические решения могут изменить структуру экономических моделей, и корреляции, существовашие исторически, прекратят свое действие”</p>

<h2 id="метаанализ">Метаанализ</h2>

<p>Институционная память (institutional memory) - это по сути коллекция всех экспериментов, удачных и не удачных, сведения о внедрении опыта и результатах, которая хранится в компании.</p>

<p>Почему это полезно? Полученные данные можно применять пятью способами:</p>

<ul>
  <li>культура экспериментов - краткоеизложение прошлых экспериментов помогает понять важность экспериментирования и спсобствует уреплению корпоративной культуры</li>
  <li>лучшие подходы к экспериментам - эксперименты не всегда следуют лучшим практикам, особенно когда внутри команды растет число экспериментов</li>
  <li>будущие инновации - для тех, кто приходит в команду очень важно понимание того, что уже испытано, что работало, а что не работало</li>
  <li>показатели - история экспериментов позволяет видеть как менялись показатели во времени. Этот ак-же позволяет вывести априорные вероятности для баесовских оценок.</li>
  <li>эмпирические исследования - эспериментальные данные позволяют вывести эмпирические оценки</li>
</ul>

<h2 id="этика-контроллируемых-экспериментов">Этика контроллируемых экспериментов</h2>

<ul>
  <li>уважение к людям</li>
  <li>полезность для людей</li>
  <li>справделивость (распределение рисков и выгод)</li>
  <li>возможность выбора для участников</li>
</ul>

<h2 id="дополнительные-методы-оценки">Дополнительные методы оценки</h2>

<ul>
  <li>исследование пользовательского опыта</li>
  <li>фокус-группы</li>
  <li>человеческая оценка</li>
  <li>внешние данные</li>
  <li>опросы</li>
  <li>аналитика на основе логирования</li>
</ul>

<p>Анализ на основе логов (ретроспективный анализ) полезен по следующим причинам:</p>

<ul>
  <li>позволяет развить понимание какие показатели важны</li>
  <li>позволяет увидеть как потенциальные показатель мог работать в прошлом</li>
  <li>выработка идей для А/Б тестов на основе полученных базовых знаний</li>
  <li>изучение реализуемости идеи</li>
  <li>выявление естественных экспериментов, которые происходят время от времени из-за внешних обстоятельств (анпример при измененеии каких-то параметро по умолчанию)</li>
  <li>наблюдение причинно -следственных связей, часто в случаях, когда прямой эксперимент невозможен</li>
</ul>

<h2 id="исследование-причинно-следственных-связей">Исследование причинно-следственных связей</h2>

<p><strong>Когда контроллируемые эксперименты невозможны?</strong></p>

<ul>
  <li>организация не контроллирует проверяемое причинное действие</li>
  <li>когда подопытных слишком мало</li>
  <li>при формировании контрольной популяции формируются слишком большие издержки</li>
  <li>когда изменение стоит дорого по сравнению с воспринимаемой ценностью (например, когда пытаются оценить сколько пользователей уйдет, если случится какое-то нежелательное событие)</li>
  <li>когда невозможно рандомизировать единицу рандомизации должным образом</li>
  <li>когда тест неэтичен или незаконен</li>
</ul>

<h3 id="планы-для-для-наблюдательных-исследований-причинно-следственных-связей">Планы для для наблюдательных исследований причинно-следственных связей</h3>

<p><strong>Прерывистый временной ряд (interupted time series ITS)</strong> - квазиэкспериментальный план, в котором возможно контроллировать измерения в своей системе, но невозможно рандомизировать воздействие. Тогда используется одна популяция для теста и контроля и измеряется то, что она испытывает с течением времени.</p>

<p>Наиболее распространенная проблема ITS - это временные эффекты, т.к. сравнения производятся в разное время. Важно так-же гарантировать, что вы не приписываете какой-либо эффект изменению, хотя на самом деле имеется некий совместный эффект. Это можно разрешить путем многократного переключения между воздействием и бездействием.</p>

<p>Другая проблема - взаимодействие с пользователем, в результате которого пользователь может заметить, что их опыт переключается, что может привести к раздражению и недовольству.</p>

<p><strong>Эксперименты с чередованием</strong> - план используется для оценки алгоритмов ранжирования. Алгоритм эксперимента чередует рекоторы должен показывать каждый из алгоритмов ранжирования с удалением повторов. В результате сравнивается рейтинг кликов двух алгоритмов.</p>

<p>Способ ограничен, т.к. результаты должны быть однородны. Если, существует предопределенная логика позиционирования или объекты тестирования выглядят по разному - начинаются сложности.</p>

<p>Метод разрывной регрессии (regression discontinuity design, RDD) - план эксперимента, который можно использовать всякий раз, когда существует четкий порог, идентифицирующий исследуемую популяцию. В этом случае мы можем определить популяцию, которая чуть ниже порога как контрольную, а популяцию, которая выше, как тестовую.</p>

<p>В RDD поведение пользователя может быть искажено другими факторами, связанными с тем же порогом</p>

<p><strong>Иеструментальные переменные (instrumental variables, IV)</strong> - метод пытается аппроксимировать случайное назначение. Цель состоит в том, чтобы найти инструмент, который позволяет аппроксимировать случайное распределение. Иногда возможно проведение и <strong>естественных экспериментов (natural experiments)</strong>, где практически случайны.</p>

<p><strong>Отбор подобного по склонности (propensity score matching, PSM)</strong> - сегментация на основании общих специфических свойств или склонностей к чему либо. Идея заключавется в том ,чтобы гарантировать, что раздличие между контрольной и тестовой популяцией не связано с изменением состава популяции. PSM вместо сопоставления единиц на ковариантах сопоставляет одно число - сформулированную оценку склонности.</p>

<p>Проблема PSM в том, что учитываются только наблюдаемые варианты, неучтенные факторы могут привести к скрытым предубеждениям. Кроме того проблемой является наложение факторов.</p>

<p><strong>Дифференциальная разница (difference in differences, DD или DID)</strong> - учитывается разница в контрольной и подопытной группах. Иными словами, групапы могут различаться, но “двигаться параллельно”. Метод обычно используется в географических экспериментах.</p>

<h3 id="ловушки-причинно-следственных-связей">Ловушки причинно-следственных связей</h3>

<ul>
  <li>наличие нераспознанной общей причины</li>
  <li>ложные или обманчивые корреляции</li>
</ul>

<h2 id="эксперименты-на-стороне-клиента">Эксперименты на стороне клиента</h2>

<p>Различия между серверной и клиентской стороной:</p>

<ul>
  <li>процесс выпуска клиентских приложений (в отличии от, к примеру, web-сайтов, где выпуск полностью контроллируется сервером) зависит как от стороны владельца площадки (к примеру магазина приложений), так и стороны климента. Из-за этого выпуски могут не попадать к клиентам вовремя. В результате, в любой момент времени существует несколько версий приложения, котоыре придется поддерживать.</li>
  <li>обмен данными между клиентмо и сервером может зависеть от качества связи и ее доступности. приложение может находиться долго офлайн. На это влияют: качество подключения, пропускная способность канала, заряд батареи, производительность устройства клиента, память и ее доступность на устройстве, аппаратные и программные ограничения.</li>
</ul>

<p>В качестве компромисса предполагается возможность для приложения работать офлайн, а так-же собственное хранилище данных на устройстве. Следствием компромисса является:</p>

<ul>
  <li>необходимо предвидеть изменеения как можно раньше. чтобы планировать эксперименты как можно раньше и тщательнее. АБ-тесты придется поставлять с релизом и ждать следующего, если что-то пошло не так.</li>
  <li>возможны задержки данных и времени выпуска. т.к. не все пользовательские устройства получат новую версию, кроме того обновления могут не вступить в силу из-за особенностей загрузки или принятия пользователем изменеений. Таких устройств может оказаться много.</li>
  <li>устройства могут находиться офлайн. Необходимо создать систему кеширования данных эксперимента</li>
  <li>возможно придется анализировать данные на стороне клиента</li>
  <li>нагрузка на устройстве клиента может повлиять на работу приложения. Это надо отслеживать</li>
  <li>возможно придется запускать новую версию поэтапно, часть пользователей оставляя на старой, однако это может быть непрактично с точки зрения накладных расходов на устройстве пользователя.</li>
  <li>у пользователя может быть множество разных устройств и разных программных платформ на них. В итоге один пользователь может оказаться в разных группах тестирования, имея несколько устройств. При этом данные с разных устройств могут синхронизироваться.</li>
</ul>

  </div>
</article>


    </main>

    <footer role="banner">
<div class="border-top-thin clearfix mt-2 mt-lg-4">
    <div class="container mx-auto px-2">
      <p class="col-8 sm-width-full left py-2 mb-0"><a href="/myknowlegebase/">My knowledge base</a> проект поддерживается <a class="text-accent" href="https://github.com/KonstantinKlepikov">KonstantinKlepikov</a></p>
      <ul class="list-reset right clearfix sm-width-full py-2 mb-2 mb-lg-0">
        <li class="inline-block mr-1">
          <a href="https://twitter.com/share" class="twitter-share-button" data-hashtags="My knowledge base">Tweet</a> <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
        </li>
      </ul>
    </div>
  </div>
</footer>

  </body>

</html>

<script type="text/javascript">
  // Hack: Replace page-link with "Page Title"
  document.querySelectorAll(".markdown-body a[title]").forEach((a) => {
    a.innerText = a.title;
  });
  // Hack: Remove .md extension from wikilinks to get the html in jekyll
  document.querySelectorAll("a").forEach(l => {
    if (l.href.endsWith('.md')) {
      l.href = l.href.substring(0, l.href.length-3)
    }
  })
</script>